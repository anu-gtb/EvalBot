{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVIrSxb0hyd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xuBolr2W3S2W"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(r'C:\\Users\\DELL\\Documents\\MAJOR PROJECT\\train_preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYnzbL5u3uaP",
        "outputId": "92f53559-eafa-48ab-a348-523f2a4772fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(99887, 3)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=data.sample(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6attqih_6kIe",
        "outputId": "b12f3c34-86f1-4f49-a767-34ccc118d6b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99887 entries, 0 to 99886\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   similarity  99887 non-null  int64 \n",
            " 1   sentence1   99887 non-null  object\n",
            " 2   sentence2   99884 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6dB2OqaM6plf"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "-NethC4d6t0p",
        "outputId": "182748d0-5448-4621-d696-ccc3fc2f3b82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "similarity    0\n",
              "sentence1     0\n",
              "sentence2     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bZJYBI7G4A7N"
      },
      "outputs": [],
      "source": [
        "training_data=[(row['sentence1'],row['sentence2']) for index,row in data.iterrows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqP1FP9e1Tig",
        "outputId": "77b1eca8-2b95-4b3f-e467-775b5252f0d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name='bert-base-uncased'\n",
        "tokenizer=BertTokenizer.from_pretrained(model_name)\n",
        "model=BertForSequenceClassification.from_pretrained(model_name,num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5lEGzJ5q17Dh"
      },
      "outputs": [],
      "source": [
        "def tokenization(sent1,sent2):\n",
        "  encoded=tokenizer.encode_plus(\n",
        "      sent1,sent2,\n",
        "      add_special_tokens=True,\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      return_tensors='pt'\n",
        "  )\n",
        "  input_ids=encoded['input_ids']\n",
        "  attention_masks=encoded['attention_mask']\n",
        "  return input_ids,attention_masks\n",
        "\n",
        "input_ids=[]\n",
        "attention_masks=[]\n",
        "for sent1,sent2 in training_data:\n",
        "  ids,masks=tokenization(sent1,sent2)\n",
        "  input_ids.append(ids[0])\n",
        "  attention_masks.append(masks[0])\n",
        "\n",
        "input_ids=pad_sequence(input_ids,batch_first=True)\n",
        "attention_masks=pad_sequence(attention_masks,batch_first=True)\n",
        "similarity_tensor=torch.tensor(data['similarity'].values)\n",
        "dataset=TensorDataset(input_ids,attention_masks,similarity_tensor)\n",
        "dataloader=DataLoader(dataset,batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79S5ij8NUUVU",
        "outputId": "18fa3c65-30f5-4afd-a263-20a17312d5af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99884"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6BbYFpstvQ0",
        "outputId": "13ea4736-aad5-4ce4-9131-67b236b744bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSpA_1A3uVxr"
      },
      "outputs": [],
      "source": [
        "POPULATION_SIZE = 10\n",
        "GENERATIONS = 3\n",
        "MUTATION_RATE = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "5XRfv8lGuLdz",
        "outputId": "4556d46c-86e3-434d-9a57-67e3ac39d648"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 68\u001b[0m\n\u001b[0;32m     64\u001b[0m         population\u001b[38;5;241m=\u001b[39mparents\u001b[38;5;241m+\u001b[39mmutated\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_individual\n\u001b[1;32m---> 68\u001b[0m best_parameter\u001b[38;5;241m=\u001b[39m\u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameter :\u001b[39m\u001b[38;5;124m'\u001b[39m, best_parameter)\n",
            "Cell \u001b[1;32mIn[16], line 54\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[1;34m(model, dataloader, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m best_fitness\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(GENERATIONS):\n\u001b[1;32m---> 54\u001b[0m     fitness_scores\u001b[38;5;241m=\u001b[39m[\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m individual \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(fitness_scores)\u001b[38;5;241m<\u001b[39mbest_fitness:\n\u001b[0;32m     57\u001b[0m         best_fitness\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(fitness_scores)\n",
            "Cell \u001b[1;32mIn[16], line 20\u001b[0m, in \u001b[0;36mfitness\u001b[1;34m(individual, model, dataloader, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m     total_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m=\u001b[39mtotal_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def initialize_population(population_size):\n",
        "  population=[]\n",
        "  for _ in range(population_size):\n",
        "      learning_rate=(random.uniform(1,9))*10**-5\n",
        "      population.append({'learning_rate':learning_rate})\n",
        "  return population\n",
        "\n",
        "def fitness(individual,model,dataloader,device):\n",
        "    optimizer=AdamW(model.parameters(),lr=individual['learning_rate'])\n",
        "    #criterion=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    for batch in dataloader:\n",
        "        input_ids,attention_masks,labels=batch\n",
        "        input_ids,attention_masks,labels=input_ids.to(device),attention_masks.to(device),labels.to(device)\n",
        "        outputs=model(input_ids,attention_mask=attention_masks,labels=labels)\n",
        "        loss=outputs.loss\n",
        "        total_loss+=loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    loss=total_loss/len(dataloader)\n",
        "    return loss\n",
        "\n",
        "def selection(population,fitness_scores):\n",
        "    sorted_population=[p for _,p in sorted(zip(fitness_scores,population))]\n",
        "    num_parents=len(population)//2\n",
        "    if num_parents==0  and len(population)>0:\n",
        "        return [population[0]]\n",
        "    return sorted_population[:num_parents]\n",
        "\n",
        "def cross_over(parents):\n",
        "    children=[]\n",
        "    for i in range(len(parents),2):\n",
        "        if i+1<len(parents):\n",
        "            parent1=parents[i]\n",
        "            parent2=parents[i+1]\n",
        "            child1={'learning_rate':(parent1['learning_rate']+parent2['learning_rate'])/2}\n",
        "            child2={'learning_rate':(parent1['learning_rate']+parent2['learning_rate'])/2}\n",
        "            children.extend([child1,child2])\n",
        "    return children\n",
        "\n",
        "def mutate(individual,mutation_rate):\n",
        "    if random.random()<mutation_rate:\n",
        "        individual['learning_rate']*=10**random.uniform(-0.5,0.5)\n",
        "    return individual\n",
        "\n",
        "def genetic_algorithm(model,dataloader,device):\n",
        "    population=initialize_population(POPULATION_SIZE)\n",
        "    best_individual=None\n",
        "    best_fitness=float('inf')\n",
        "\n",
        "    for generation in range(GENERATIONS):\n",
        "        fitness_scores=[fitness(individual,model,dataloader,device) for individual in population]\n",
        "\n",
        "        if min(fitness_scores)<best_fitness:\n",
        "            best_fitness=min(fitness_scores)\n",
        "            best_individual=population[fitness_scores.index(min(fitness_scores))]\n",
        "\n",
        "        print(f'Generation {generation+1}, Best Fitness score : {best_fitness}')\n",
        "        parents=selection(population,fitness_scores)\n",
        "        children=cross_over(parents)\n",
        "        mutated=[mutate(child,MUTATION_RATE) for child in children]\n",
        "        population=parents+mutated\n",
        "\n",
        "    return best_individual\n",
        "\n",
        "best_parameter=genetic_algorithm(model,dataloader,device)\n",
        "\n",
        "print('Best parameter :', best_parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuS__xoixwZr"
      },
      "outputs": [],
      "source": [
        "''' optimizer=AdamW(model.parameters(),lr=best_parameter['learning_rate])\n",
        "epochs=100\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total_loss=0\n",
        "  for batch in dataloader:\n",
        "    input_ids,attention_masks,labels=batch\n",
        "    input_ids,attention_masks,labels=input_ids.to(device),attention_masks.to(device),labels.to(device)\n",
        "    outputs=model(input_ids,attention_mask=attention_masks,labels=labels)\n",
        "    loss=outputs.loss\n",
        "    total_loss+=loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  loss=total_loss/len(dataloader)\n",
        "  print('Epoch : ',epoch+1,'----> Loss : ',loss)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqyjl4ini_PQ"
      },
      "outputs": [],
      "source": [
        "#model.save_pretrained('fine-tuned-bert3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
